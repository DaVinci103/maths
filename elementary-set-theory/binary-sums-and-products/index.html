<!DOCTYPE html>
<html>
<head>
\[
\newcommand{\NN}{\mathbb{N}}
\newcommand{\id}{\textrm{id}}
\]
 
	<title>Binary Sums and Products - DV103</title>
	<link rel="stylesheet" href="../../style.css">

	<script>
	MathJax = {
		loader: {load: ['[tex]/html']},
		tex: {
			inlineMath: {'[+]': [['$', '$']]},
			packages: {'[+]': ['html', 'ams']}
		},
	};
	</script>
	<script defer src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
</head>
<body>
	<h1>Binary Sums and Products</h1>
	<h2>Products</h2>
	<p>
		Any two given sets $A$ and $B$ have a <b>product</b>, which consists of:
	</p>

	<ul>
		<li>A set $A \times B$, also sometimes refered to as the product;</li>
		<li>Functions $A \times B \to A$ and $A \times B \to B$, called <b>projections</b>.</li>
	</ul>

	<p>
		The set $A \times B$ consists of all pairs of elements $(a,b)$ with $a \in A$ and $b \in B$. For example, $(6,(3,44))$ is an element of $\NN \times (\NN \times \NN)$. The projection functions make clear how $A \times B$ relates to $A$ and $B$.
	</p>
\[
\begin{array}{rrcl}
\pi_0: & A \times B & \to & A \\
& p & \mapsto & p_0 \\
\pi_1: & A \times B & \to & B \\
& p & \mapsto & p_1
\end{array}
\]
	<p>
		We'll denote these projections by $\pi_0$ and $\pi_1$, or sometimes $\pi_0^{A \times B}$ and $\pi_1^{A \times B}$ to indicate which project they're the projection functions of. We call $\pi_0$ the <b>left projection</b> and $\pi_1$ the <b>right projection</b>. The left projection chooses $a$ from a pair $(a,b)$ and the right projection chooses $b$ from a pair $b$. For a pair $p$, we write the left- and right projection of $p$ as $p_0$ and $p_1$ respectively. For example, $((6,(3,44))_1)_0 = (3,44)_0 = 3$.
	</p>

	<p>
		There are three basic axioms regarding the pair construction $(-,-)$ and the projections $\pi_0$ and $\pi_1$:
	</p>

	<ul>
		<li>For $a \in A$ and $b \in B$, $(a,b)_0 = a$;</li>
		<li>For $a \in A$ and $b \in B$, $(a,b)_1 = b$;</li>
		<li>For $p \in A \times B$, $(p_0,p_1) = p$.</li>
	</ul>

	<p>
		The first two axioms are basically just the definitions of the two projections. The last axiom might be a bit confusing at first. Basically, it states that no pair contains more information than its left and right projection, similar to how a function contains no more information than its function values. In other words, closer to the actual statement of the axiom, all pairs $p \in A \times B$ can be constructed with the same pair construction $(-,-)$. Without it, there might be multiple pairs $p \neq p'$ with $p_0 = p'_0$ and $p_1 = p'_1$.
	</p>

	<p>
		When we write a ternary product like $A \times B \times C$, it's unclear whether we mean $(A \times B) \times C$ or $A \times (B \times C)$. Products don't seem to be associative at first: the first projection function of $(A \times B) \times C$ is an $(A \times B) \times C \to A \times B$ function, while the first projection function of $A \times (B \times C)$ is from $A \times (B \times C)$ to $A$. So it's not clear which one we should choose as the correct interpretation. However, the underlying set doesn't actually seem to change, only the projection functions around it. From the set $A \times B \times C$ of triplets $(a,b,c)$ for $a \in A$, $b \in B$ and $c \in C$, we can define a left projection $\pi_0^{(A \times B) \times C}: A \times B \times C \to A \times B$ that maps $(a,b,c)$ to $(a,b)$, or we can define a left projection $\pi_0^{A \times (B \times C)}: A \times B \times C \to A$ that maps $(a,b,c)$ to $a$. But we still want to know which projection function to use when interpreting $(a,b,c)_0$.
	</p>

	<p>
		Neither option is really practical. If we haver longer tuples $(a_0,\ldots,a_n)$, we have to apply a lot of projection functions to get to an element somewhere in the middle. So, instead of choosing either, we'll just use more projection functions $\pi_0: A \times B \times C \to A$, $\pi_1: A \times B \times C \to B$ and $\pi_2: A \times B \times C \to C$, where $(a,b,c)_0 = a$, $(a,b,c)_1 = b$ and $(a,b,c)_2 = c$. Generally, $(a_0,\ldots,a_n)_i = a_i$. In cases where the exact choice does matter, for example if a theorem or definition applies specifically to binary products, we assume $\times$ is right-associative, meaning that $A \times B \times C = A \times (B \times C)$.
	</p>


	<h2>Multi-Valued Functions</h2>
	<p>
		A <b>multi-valued</b> function is a function whose codomain is a product. If the codomain of a function $f$ is a product of $n$ sets we call it an $n$-valued function. For example, the function
	</p>
\[
\begin{array}{rrcl}
\Delta_A: & A & \to & A \times A \\
& a & \mapsto & \Delta_A(a)
\end{array}
\]
	<p>
		defined by $\Delta_A(a) = (a,a)$, called the <b>diagonal</b> of $A$, is a two-valued function. We often omit $A$ when writing the diagonal map, simply denoting it as $\Delta$. Another example is the function $f: \NN \to \NN \times \NN$ that factors $n$ into $(a,b)$, where $n = a \cdot b^2$ and $a$ is a square-free number. For example, $f(12) = (3,2)$ as $12 = 3 \cdot 2^2$ and $3$ is square-free.
	</p>

	<p>
		It seems like a multi-valued function really is just multiple functions in one. For example the function $f$ that factors a number into a square-free part and a square can be seen as two functions $g: \NN \to \NN$ and $h: \NN \to \NN$, where $g$ maps a number to its square-free part, and $h$ maps a number to (the square-root of) the square part. Thus, $g(12) = 3 = f(12)_0$ and $h(12) = 2 = f(12)_1$. Since pairs are uniquely determined by its projections (because of the third axiom of pairs), we can give a complete definition of a multi-valued function by defining only the projections of its function values. For example,
	</p>
\begin{eqnarray}
k(n)_0 & = & n + 6 \\
k(n)_1 & = & 2 \cdot n \\
k(n)_2 & = & n^3
\end{eqnarray}
	<p>
		is a complete definition of a function $k: \NN \to \NN \times \NN \times \NN$.
	</p>

	<p>
		Given a list of functions $f_0: A \to B_0, \ldots, f_n: A \to B_n$, each with the same domain, we call the unique multi-valued function $f: A \to B_0 \times \cdots \times B_n$  for which, for all $0 \le i \le n$, $\pi_i \circ f = f_i$, the <b>tuple</b> of $f_0, \ldots, f_n$. We denote this tuple as $(f_0,\ldots,f_n)$. Using the square-factoring example above, we thus have $f = (g,h)$. Tuples of functions share notation with pairs and tuples of elements. This is because they're basically the same thing. We'll often use a pair $(g,h)$ as both a function tuple as a pair of elements, so we write $(g,h)_0$ to mean $g$ (using $(g,h)$ as a pair of elements, this can also be interpreted as a shorthand for $\pi_0 \circ (g,h)$) and $(g,h)(n)$ to mean $(g(n),h(n))$ (using $(g,h)$ as a tuple of functions).
	</p>

	<p>
		One last example of a multi-valued function is the bijection between $A \times B$ and $B \times A$ that maps a pair $(a,b)$ to $(b,a)$. Using function tuples, this bijection can be written as $(\pi_1,\pi_0)$.
	</p>


	<h2>Functions with Multiple Arguments</h2>
	<p>
		A function a product of $n$ sets as domain is called an <b>$n$-ary</b> function (binary for $n=2$, ternary for $n=3$, etc). For $f: A_0 \times \cdots \times A_{n-1} \to B$, we write $f$ applied to the tuple $(a_0,\ldots,a_{n-1})$ as $f(a_0,\ldots,a_{n-1})$ and we call the elements $a_0 \in A_0, \ldots, a_{n-1} \in A_{n-1}$ its <b>arguments</b>. Unlike multi-valued functions, $n$-ary functions aren't simply multiple functions in one.
	</p>

	<p>
		We already saw a binary function in the last part: the bijection $(\pi_1,\pi_0)$. Another example is multiplication on natural numbers: it takes two natural numbers $m$ and $n$ as arguments, and gives back a single number $m \cdot n$. Multiplication on natural numbers is an operator. An ($n$-ary) <b>operator</b> on $A$ is a function $f: \underbrace{A \times \cdots \times A}_n \to A$ where the domain is an $n$-fold product of the codomain, this product is sometimes abbreviated as $A^n$. The empty product is often defined as the one-element set $\mathbf{1}$, so a nullary ($0$-ary) operator on $A$ is sometimes used to refer to a $\mathbf{1} \to A$ function, or an element of $A$.
	</p>

	<p>
		There are many kinds of operators. We already saw two kinds of unary operators in the first chapter: idempotent operators $f: A \to A$ for which $f^2 = f$, and involutions $f: A \to A$ for which $f^2 = \id_A$.
	</p>

	<p>
		We often write binary operators with infix notation. Thus, for an operator ${\star}: A \times A \to A$, instead of writing ${\star}(x,y)$ for $\star$ applied to $(x,y)$, we often write $x \star y$. The two most important properties of binary operators are associativity and commutativity. An operator $\star$ is said to be <b>associative</b> if $(x \star y) \star z = x \star (y \star z)$ for all $x,y,z \in A$. If $\star$ is associative, we often write $x \star y \star z$ without parenthesis. Associativity allows us to combine elements unambiguously. An example of an associative operator is string concatenation: if we concatenate string "a", "b" and "c", it doesn't matter if we concatenate "a" with "b" first, or if we first concatenate "b" with "c", we'll always end up with the string "abc". An operator ${\star}: A \times A \to A$ is <b>commutative</b> if $x \star y = y \star x$ for all $x,y \in A$. For example, adding two natural numbers is commutative. We often talk about commuting of individual elements: we say $x$ and $y$ <b>commute</b> (with respect to $\star$) if $x \star y = y \star x$.
	</p>

	<p>
		We can generalize commutativity to operators with more arguments: an operator $f: A^n \to A$ is said to be <b>symmetric</b> if swapping any two arguments doesn't change the function value. More properties of operators will be introduced in the next chapter, where we'll look at the operators $\cap$ and $\cup$.
	</p>


	<h2>Sums</h2>
	<p>
		Any two given sets $A$ and $B$ have a <b>sum</b>, which consists of:
	</p>

	<ul>
		<li>A set $A+B$, also sometimes referred to as the sum;</li>
		<li>Functions $A \to A+B$ and $B \to A+B$, called <b>coprojections</b>.</li>
	</ul>

	<p>
		The set $A+B$ consists of all elements of $A$ and $B$ combined. These elements are labelled with if they come from the left set $A$ or the right set $B$. For an element $a \in A$, its corresponding element in $A+B$ is denoted as $\kappa_0(a)$, and for $b \in B$, its corresponding element in $A+B$ is denoted $\kappa_1(b)$. The $\kappa_0$/$\kappa_1$ indicates which set the element came from. For example, if we consider the sum $\NN + \NN$, then $\kappa_0(6) \neq \kappa_1(6)$ as one $6$ comes from the left $\NN$, while the other $6$ comes from the right $\NN$.
	</p>
\[
\begin{array}{rrcl}
\kappa_0: & A & \to & A+B \\
\kappa_1: & B & \to & A+B
\end{array}
\]
	<p>
		The functions $\kappa_0: A \to A+B$ and $\kappa_1: B \to A+B$ are the coprojections of $A+B$. Besides allowing us to write elements of $A+B$, they also make clear how the sets $A$ and $B$ relate to their sum $A+B$. We sometimes denote these coprojections as $\kappa_0^{A+B}$ and $\kappa_1^{A+B}$. We call $\kappa_0$ the <b>left coprojection</b> and $\kappa_1$ the <b>right coprojection</b>. Similar to how we use more projections $\pi_0,\ldots,\pi_n$ for larger products $A_0 \times \cdots \times A_n$, we'll also use more coprojections $\kappa_0,\ldots,\kappa_n$ for larger sums $A_0+\cdots+A_n$.
	</p>

	<p>
		For products, we used the pair constructor to introduce elements of the products $A \times B$ and the projections to eliminate those elements. For sums, coprojections introduce elements of $A+B$, but eliminating elements is a bit more difficult. We cannot simply define a functions from $A+B$ to $A$ or $B$, as this would allow us to create elements of $A$ from elements of $B$ (by using the elimination function to $A$ on $\kappa_1(b)$), or vice-versa. We also can't define an elimination function to be $A+B \to A+\mathbf{1}$, where the $\mathbf{1}$ is a sort-of "error" corresponding to giving an element from the wrong set (i.e. from $B$), as then we just trade one sum for another. Sum elimination is actually more similar to function tuples, as opposed to the simpler operations on elements (pairing, projections) used in products. The usual way to eliminate a sum is using is using cotuples, which are explained in the next part.
	</p>


	<h2>Cotuples</h2>
	<p>
		The solution to our problem in the last part, eliminating sums, is to first map both sets $A$ amd $B$ to a common set $C$, and then combining both maps into one. Given two functions $f: A \to C$ and $g: B \to C$, $[f,g]$ is a function from $A+B$ to $C$ called the <b>cotuple</b> of $f$ and $g$. Similar to pairing and projections, we have three rules for how coprojections work with cotuples. The first two basically define the cotuple:
	</p>
\[
\begin{eqnarray}
[f,g](\kappa_0(a)) & = & f(a) \\
[f,g](\kappa_1(b)) & = & g(b)
\end{eqnarray}
\]
	<p>
		The third axiom mirrors the third axiom of products. It basically states all elements of $A+B$ are either of the form $\kappa_0(a)$ or $\kappa_1(b)$. The actual formulation is, for a function $h: A+B \to C$,
	</p>
\[[h \circ \kappa_0, h \circ \kappa_1] = h\]
	<p>
		If you think a little about this axiom, it says that a function out of $A+B$ is uniquelly determined by how it's defined on elements of the form $\kappa_0(a)$ and $\kappa_1(b)$. To see how this implies all elements of $A+B$ are either of the form $\kappa_0(a)$ or $\kappa_1(b)$: take any two functions $f: A \to \mathbf{2}$ and $g: B \to \mathbf{2}$ and consider the cotuple $[f,g]: A+B \to \mathbf{2}$. Assuming not all elements of $A+B$ are of the form $\kappa_0(a)$ or $\kappa_1(b)$, take $x \in A+B$ to be such an element. The cotuple $[f,g]$ has $A+B$ as domain, so $[f,g](x)$ is defined and is either $0_{\mathbf{2}}$ or $1_{\mathbf{2}}$. Now, define a function $h: A+B \to \mathbf{2}$ by $h(y) = [f,g](y)$ for all $y \in A+B$ not equal to $x$, and $h(x)$ is opposite of whatever $[f,g](x)$. Since $x$ is neither of the form $\kappa_0(a)$ or $\kappa_1(b)$, $h \circ \kappa_0$ is still equal to $f$, and $h \circ \kappa_1$ still equals $g$. By the third axiom of sums, $[h \circ \kappa_0, h \circ \kappa_1] = h$, however, we know that $[h \circ \kappa_0, h \circ \kappa_1] = [f,g] \neq h$ because $[f,g](x) \neq h(x)$. This means such an element $x$ cannot exist.
	</p>

	<p>
		We can also define cotuples on more functions. If we have functions $f_0: A_0 \to B, \ldots, f_n: A_n \to B$, then $[f_0,\ldots,f_n]$ is a cotuple from $A_0+\cdots+A_n$ to $B$ where $[f_0,\ldots,f_n] \circ \kappa_i = f_i$.
	</p>


	<h2>Sums and Products of Functions</h2>
	<p>
		W.I.P
	</p>
	
	<p>
		<a href="../sets-and-functions">&leftarrow;</a>
		<a href="../..">..</a>
		<a style="color:var(--ctp-mocha-overlay2)">&rightarrow;</a>
	</p>
</body>
</html>
